{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "roopagmlresourcegp"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/Filtertransform')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 filter(equals(DEPARTMENT_ID, 50)) ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['payroll_emp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1_surrogate')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "output1dataset",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> emp",
						"emp keyGenerate(output(Emp_Key as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 select(mapColumn(",
						"          Emp_Key,",
						"          EMPLOYEE_ID,",
						"          FIRST_NAME,",
						"          LAST_NAME,",
						"          EMAIL,",
						"          PHONE_NUMBER,",
						"          HIRE_DATE,",
						"          JOB_ID,",
						"          SALARY,",
						"          COMMISSION_PCT,",
						"          MANAGER_ID,",
						"          DEPARTMENT_ID",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Name as string,",
						"          Category as string,",
						"          Status as string,",
						"          Error as string",
						"     ),",
						"     partitionFileNames:['surrgogate.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflowJoin')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "Emp"
						},
						{
							"dataset": {
								"referenceName": "Deptdataset",
								"type": "DatasetReference"
							},
							"name": "Dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "Output"
						}
					],
					"transformations": [
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Emp",
						"source(output(",
						"          DEPARTMENT_ID as string,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Dept",
						"Emp, Dept join(Emp@DEPARTMENT_ID == Dept@DEPARTMENT_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> Output"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_aggregate')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 aggregate(groupBy(DEPARTMENT_ID),",
						"     EMPLOYEE_ID = count(EMPLOYEE_ID)) ~> aggregate1",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['emp_count.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_alterrow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "alterRow1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as integer,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as integer,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"select1 alterRow(insertIf(equals(EMPLOYEE_ID,199)),",
						"     deleteIf(equals(Name,'Donald')),",
						"     updateIf(equals(Name,'Douglas'))) ~> alterRow1",
						"source1 select(mapColumn(",
						"          Name = FIRST_NAME,",
						"          EMPLOYEE_ID,",
						"          location = COMMISSION_PCT,",
						"          SALARY",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Name as string,",
						"          ID as integer,",
						"          LOC as string,",
						"          SAL as decimal(10,2)",
						"     ),",
						"     deletable:true,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['ID'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Name,",
						"          ID = EMPLOYEE_ID,",
						"          LOC = location,",
						"          SAL = SALARY",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_asserttransform')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "Deptdataset",
								"type": "DatasetReference"
							},
							"name": "dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "assert1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          DEPARTMENT_ID as integer,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> dept",
						"source1, dept assert(expectTrue(isNull(toDate(HIRE_DATE, 'dd-mmm-yy')), false, 'assert1', null, 'check data'),",
						"     expectUnique(EMPLOYEE_ID, false, 'assert2', null, 'check unique'),",
						"     expectUnique(source1@DEPARTMENT_ID, dept@DEPARTMENT_ID, false, 'assert3', null, 'check exists')) ~> assert1",
						"assert1 derive(iserrorrow = isError(),",
						"          deptexists = hasError('assert3')) ~> derivedColumn1",
						"derivedColumn1 filter(iserrorrow==false()) ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_branch')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "emp"
						},
						{
							"dataset": {
								"referenceName": "Deptdataset",
								"type": "DatasetReference"
							},
							"name": "dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> emp",
						"source(output(",
						"          DEPARTMENT_ID as string,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> dept",
						"emp aggregate(groupBy(DEPARTMENT_ID),",
						"     EMPLOYEE_ID = count(EMPLOYEE_ID)) ~> aggregate1",
						"emp, dept join(emp@DEPARTMENT_ID == dept@DEPARTMENT_ID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['test1.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['test2.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_cahcesink')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference"
							},
							"name": "empdb"
						},
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "empblob"
						}
					],
					"sinks": [
						{
							"name": "cachedmaxempid"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "SELECT"
						}
					],
					"scriptLines": [
						"source(output(",
						"          maxid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     query: 'select max(id) as maxid from customer',",
						"     format: 'query') ~> empdb",
						"source(output(",
						"          EMPLOYEE_ID as integer,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as integer,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empblob",
						"empblob keyGenerate(output(EMPID as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 derive(EMPID = EMPID + cachedmaxempid#outputs()[1].maxid) ~> derivedColumn1",
						"derivedColumn1 select(mapColumn(",
						"          FIRST_NAME,",
						"          empid = EMPID,",
						"          JOB_ID,",
						"          SALARY",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> SELECT",
						"empdb sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 1,",
						"     mapColumn(",
						"          maxid",
						"     )) ~> cachedmaxempid",
						"SELECT sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Name as string,",
						"          ID as integer,",
						"          LOC as string,",
						"          SAL as decimal(10,2)",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Name = FIRST_NAME,",
						"          ID = empid,",
						"          LOC = JOB_ID,",
						"          SAL = SALARY",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_cast')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "cast1"
						},
						{
							"name": "split1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 cast(output(",
						"          EMPLOYEE_ID as integer,",
						"          HIRE_DATE as date 'dd-mm-yyyy'",
						"     ),",
						"     errors: true) ~> cast1",
						"cast1 split(isError(),",
						"     disjoint: false) ~> split1@(haserror, no)",
						"split1@haserror sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_cdc')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable3_education",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable_educationload",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     enableNativeCdc: true,",
						"     netChanges: true,",
						"     skipInitialLoad: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source1",
						"source1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          name as string",
						"     ),",
						"     deletable:true,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:true,",
						"     keys:['id'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_conditional_split')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Deptdataset",
								"type": "DatasetReference"
							},
							"name": "source1",
							"description": "Split based on dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink2"
						},
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink3"
						}
					],
					"transformations": [
						{
							"name": "split1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          DEPARTMENT_ID as integer,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 split(equals(DEPARTMENT_ID, 20),",
						"     equals(DEPARTMENT_ID, 10),",
						"     disjoint: false) ~> split1@(Deptmarketing, Deptadmin, Deptothers)",
						"split1@Deptmarketing sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['marketingdept.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"split1@Deptadmin sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['admindept.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2",
						"split1@Deptothers sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['allotherdept.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink3"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_derivedcolumn')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Deptdataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          DEPARTMENT_ID as string,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 derive(new_DEPARTMENT_NAME = upper(DEPARTMENT_NAME),",
						"          NEW_MANAGER_ID = iif(MANAGER_ID==' - ', 'unkown', MANAGER_ID)) ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_exists')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "emp"
						},
						{
							"dataset": {
								"referenceName": "Deptdataset",
								"type": "DatasetReference"
							},
							"name": "dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> emp",
						"source(output(",
						"          DEPARTMENT_ID as string,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> dept",
						"dept, emp exists(dept@DEPARTMENT_ID == emp@DEPARTMENT_ID,",
						"     negate:true,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_flowlet')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "flowlet1",
							"flowlet": {
								"referenceName": "flowlet1",
								"type": "DataFlowReference",
								"parameters": {}
							}
						},
						{
							"name": "select1"
						},
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"derivedColumn1 compose(mapColumn(",
						"          EMPLOYEE_ID,",
						"          {FIRST_NAME     } = FIRST_NAME,",
						"          DEPARTMENT_ID,",
						"          DEPARTMENT_NAME = dname",
						"     ),",
						"     composition: 'flowlet1') ~> flowlet1@(output1)",
						"source1 select(mapColumn(",
						"          EMPLOYEE_ID,",
						"          FIRST_NAME,",
						"          DEPARTMENT_ID",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 derive(dname = 'dummy') ~> derivedColumn1",
						"flowlet1@output1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_inlinedataset')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"linkedService": {
								"referenceName": "GML_Blob_Storage",
								"type": "LinkedServiceReference"
							},
							"name": "Inlineemp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          { ID} as short,",
						"          LOC as string,",
						"          SAL as integer",
						"     ),",
						"     useSchema: false,",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     format: 'delimited',",
						"     container: 'roopatpgcontainer',",
						"     folderPath: 'Input',",
						"     fileName: 'Customer.txt',",
						"     columnDelimiter: ',',",
						"     escapeChar: '\\\\',",
						"     quoteChar: '\\\"',",
						"     columnNamesAsHeader: true) ~> Inlineemp",
						"Inlineemp sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_lookuptransformation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Deptdataset",
								"type": "DatasetReference"
							},
							"name": "dept"
						},
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "lookup1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          DEPARTMENT_ID as string,",
						"          DEPARTMENT_NAME as string,",
						"          MANAGER_ID as string,",
						"          LOCATION_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> dept",
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> emp",
						"dept, emp lookup(dept@DEPARTMENT_ID == emp@DEPARTMENT_ID,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_parsetransform')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable2",
								"type": "DatasetReference"
							},
							"name": "empjson"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "parseskilla"
						},
						{
							"name": "parseaddress"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          ename as string,",
						"          skills as string,",
						"          address as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> empjson",
						"empjson parse(skills = skills ? (skill1 as string,",
						"          skill2 as string,",
						"          skill3 as string),",
						"     format: 'delimited',",
						"     columnNamesAsHeader: false,",
						"     columnDelimiter: '|',",
						"     nullValue: '') ~> parseskilla",
						"parseskilla parse(address = address ? (city as string,",
						"          country as string),",
						"     format: 'json',",
						"     documentForm: 'singleDocument') ~> parseaddress",
						"parseaddress sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['parse.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          ename,",
						"          skill1 = skills.skill1,",
						"          skill2 = skills.skill2,",
						"          city = address.city,",
						"          country = address.country",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_pivot')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "pivot_emp_data",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "pivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as string,",
						"          FirstName as string,",
						"          LastName as string,",
						"          StartDate as string,",
						"          ExitDate as string,",
						"          Title as string,",
						"          Supervisor as string,",
						"          ADEmail as string,",
						"          BusinessUnit as string,",
						"          EmployeeStatus as string,",
						"          EmployeeType as string,",
						"          PayZone as string,",
						"          EmployeeClassificationType as string,",
						"          TerminationType as string,",
						"          TerminationDescription as string,",
						"          DepartmentType as string,",
						"          Division as string,",
						"          DOB as string,",
						"          State as string,",
						"          JobFunctionDescription as string,",
						"          GenderCode as string,",
						"          LocationCode as string,",
						"          RaceDesc as string,",
						"          MaritalDesc as string,",
						"          {Performance Score} as string,",
						"          {Current Employee Rating} as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> emp",
						"emp pivot(groupBy(DepartmentType),",
						"     pivotBy(GenderCode),",
						"     {} = count(EmpID),",
						"     columnNaming: '$N$V',",
						"     lateral: true) ~> pivot1",
						"pivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_select')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> emp",
						"emp select(mapColumn(",
						"          EMP_ID = EMPLOYEE_ID,",
						"          FIRST_NAME,",
						"          LAST_NAME,",
						"          EMAIL,",
						"          MANAGER_ID,",
						"          PHONE_NO = PHONE_NUMBER",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['SELECTTRANSFORM.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_sort')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Empdataset",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdataset_noparam",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EMPLOYEE_ID as string,",
						"          FIRST_NAME as string,",
						"          LAST_NAME as string,",
						"          EMAIL as string,",
						"          PHONE_NUMBER as string,",
						"          HIRE_DATE as string,",
						"          JOB_ID as string,",
						"          SALARY as string,",
						"          COMMISSION_PCT as string,",
						"          MANAGER_ID as string,",
						"          DEPARTMENT_ID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> emp",
						"emp sort(desc(FIRST_NAME, true)) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['sort.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		}
	]
}